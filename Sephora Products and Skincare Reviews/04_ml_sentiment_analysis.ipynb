{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. ë¦¬ë·° ê°ì„± ë¶„ì„ (Sentiment Analysis)\n",
    "\n",
    "## ğŸ“Œ ì´ ë…¸íŠ¸ë¶ì˜ ëª©ì \n",
    "- ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤\n",
    "- **ë¶„ë¥˜(Classification)** ë¬¸ì œ: í…ìŠ¤íŠ¸ë¥¼ íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤ (ì¶”ì²œ vs ë¯¸ì¶”ì²œ)\n",
    "- ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ ê¸°ë³¸ì„ ë°°ì›ë‹ˆë‹¤\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "1. ë¶„ë¥˜ ë¬¸ì œì˜ ì´í•´\n",
    "2. í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ë°©ë²•\n",
    "3. í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²• (ë²¡í„°í™”)\n",
    "4. ì—¬ëŸ¬ ë¶„ë¥˜ ëª¨ë¸ ë¹„êµí•˜ê¸°\n",
    "5. í˜¼ë™ í–‰ë ¬ë¡œ ì„±ëŠ¥ ë¶„ì„í•˜ê¸°\n",
    "\n",
    "## ğŸ’¡ ì‹¤ìƒí™œ ì‘ìš©\n",
    "- ê³ ê° ë¦¬ë·° ìë™ ë¶„ë¥˜ (ê¸ì •/ë¶€ì •)\n",
    "- ì†Œì…œ ë¯¸ë””ì–´ ê°ì„± ë¶„ì„\n",
    "- ìŠ¤íŒ¸ ë©”ì¼ í•„í„°ë§\n",
    "- ë‰´ìŠ¤ ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¶„ë¥˜(Classification)ë€?\n",
    "\n",
    "### ğŸ“– ê°œë… ì„¤ëª…\n",
    "\n",
    "**ë¶„ë¥˜**ëŠ” ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •í•´ì§„ ì¹´í…Œê³ ë¦¬(í´ë˜ìŠ¤)ë¡œ ë‚˜ëˆ„ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "### íšŒê·€ vs ë¶„ë¥˜ ë¹„êµ:\n",
    "\n",
    "| êµ¬ë¶„ | íšŒê·€(Regression) | ë¶„ë¥˜(Classification) |\n",
    "|------|------------------|----------------------|\n",
    "| ì¶œë ¥ | ì—°ì†ëœ ìˆ«ì | ì¹´í…Œê³ ë¦¬ (ë²”ì£¼) |\n",
    "| ì˜ˆì‹œ | 3.5ì , 4.2ì  | ê¸ì •/ë¶€ì •, O/X |\n",
    "| ë¬¸ì œ | \"í‰ì ì´ ëª‡ ì ì¼ê¹Œ?\" | \"ê¸ì •ì¼ê¹Œ ë¶€ì •ì¼ê¹Œ?\" |\n",
    "\n",
    "### ìš°ë¦¬ê°€ í’€ ë¬¸ì œ:\n",
    "- **ì…ë ¥(Input)**: ë¦¬ë·° í…ìŠ¤íŠ¸ (\"This product is amazing!\")\n",
    "- **ì¶œë ¥(Output)**: ì¶”ì²œ ì—¬ë¶€ (ì¶”ì²œ or ë¯¸ì¶”ì²œ)\n",
    "- **ëª©í‘œ**: ë¦¬ë·° í…ìŠ¤íŠ¸ë§Œ ë³´ê³  ì‚¬ìš©ìê°€ ì œí’ˆì„ ì¶”ì²œí•˜ëŠ”ì§€ ì˜ˆì¸¡í•˜ê¸°\n",
    "\n",
    "### ì´ì§„ ë¶„ë¥˜(Binary Classification):\n",
    "- 2ê°œì˜ í´ë˜ìŠ¤ë¡œ ë‚˜ëˆ„ëŠ” ë¬¸ì œ\n",
    "- ìš°ë¦¬ ë¬¸ì œ: ì¶”ì²œ(1) vs ë¯¸ì¶”ì²œ(0)\n",
    "- ë‹¤ë¥¸ ì˜ˆì‹œ: ìŠ¤íŒ¸(1) vs ì •ìƒ(0), í•©ê²©(1) vs ë¶ˆí•©ê²©(0)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2-1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# ============================================================\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "import re  # ì •ê·œí‘œí˜„ì‹ (Regular Expression) - íŒ¨í„´ ë§¤ì¹­\n",
    "import string  # ë¬¸ìì—´ ìƒìˆ˜ (êµ¬ë‘ì , ê³µë°± ë“±)\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ê·¸ë˜í”„ í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2-2. ìì—°ì–´ ì²˜ë¦¬(NLP) ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# ============================================================\n",
    "# NLTK: Natural Language Toolkit\n",
    "# í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "import nltk\n",
    "\n",
    "# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "# stopwords: ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ëª©ë¡ (a, the, is, are ë“±)\n",
    "# punkt: ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë‚˜ëˆ„ëŠ” í† í¬ë‚˜ì´ì €\n",
    "print(\"ğŸ“¥ NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "print(\"   (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\\n\")\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# ë¶ˆìš©ì–´(Stopwords) ê°€ì ¸ì˜¤ê¸°\n",
    "from nltk.corpus import stopwords\n",
    "# ë¶ˆìš©ì–´: 'the', 'is', 'at', 'a' ê°™ì´ ì˜ë¯¸ê°€ ì—†ëŠ” í”í•œ ë‹¨ì–´ë“¤\n",
    "# ì´ëŸ° ë‹¨ì–´ë“¤ì€ ë¶„ì„ì—ì„œ ì œê±°í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# í† í¬ë‚˜ì´ì €: ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë‚˜ëˆ„ëŠ” ë„êµ¬\n",
    "# ì˜ˆ: \"I love this!\" â†’ [\"I\", \"love\", \"this\", \"!\"]\n",
    "\n",
    "# ì˜ì–´ ë¶ˆìš©ì–´ ëª©ë¡\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(\"âœ… NLTK ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"   ë¶ˆìš©ì–´ ê°œìˆ˜: {len(stop_words)}ê°œ\")\n",
    "print(f\"   ì˜ˆì‹œ: {list(stop_words)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2-3. ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# ============================================================\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë²¡í„°í™” (í…ìŠ¤íŠ¸ â†’ ìˆ«ì)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# CountVectorizer: ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ìˆ˜ë¥¼ ì„¸ëŠ” ë°©ë²•\n",
    "# ì˜ˆ: \"I love love this\" â†’ {\"I\":1, \"love\":2, \"this\":1}\n",
    "\n",
    "# TfidfVectorizer: TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "# ë‹¨ì–´ì˜ ë¹ˆë„ì™€ ì¤‘ìš”ë„ë¥¼ í•¨ê»˜ ê³ ë ¤\n",
    "# ìì£¼ ë‚˜ì˜¤ì§€ë§Œ ì—¬ëŸ¬ ë¬¸ì„œì— ê³µí†µìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” ì¤‘ìš”ë„ê°€ ë‚®ìŒ\n",
    "\n",
    "# ë¶„ë¥˜ ëª¨ë¸ë“¤\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€: ë¶„ë¥˜ë¥¼ ìœ„í•œ ì„ í˜• ëª¨ë¸ (íšŒê·€ë¼ëŠ” ì´ë¦„ì´ì§€ë§Œ ë¶„ë¥˜ ëª¨ë¸!)\n",
    "# ê²°ê³¼ë¥¼ í™•ë¥ ë¡œ ë³€í™˜ (0~1 ì‚¬ì´)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ: ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ì´ìš©í•œ í™•ë¥  ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸\n",
    "# í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— ë§¤ìš° íš¨ê³¼ì \n",
    "# 'ë‚˜ì´ë¸Œ(ìˆœì§„í•œ)'ë¼ëŠ” ì´ë¦„: ë‹¨ì–´ë“¤ì´ ë…ë¦½ì ì´ë¼ê³  ê°€ì • (ì‹¤ì œë¡œëŠ” ì•„ë‹ˆì§€ë§Œ)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°: ì—¬ëŸ¬ ê²°ì • íŠ¸ë¦¬ë¥¼ ì‚¬ìš©\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "# SVM (Support Vector Machine): ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ëŠ” ìµœì ì˜ ê²½ê³„ì„ ì„ ì°¾ëŠ” ëª¨ë¸\n",
    "# LinearSVC: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ëŠ” ë¹ ë¥¸ ë²„ì „\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,      # ì •í™•ë„: ì „ì²´ ì¤‘ ë§ì¶˜ ë¹„ìœ¨\n",
    "    precision_score,     # ì •ë°€ë„: ê¸ì •ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ê¸ì • ë¹„ìœ¨\n",
    "    recall_score,        # ì¬í˜„ìœ¨: ì‹¤ì œ ê¸ì • ì¤‘ ê¸ì •ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨\n",
    "    f1_score,           # F1: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· \n",
    "    classification_report,  # ì¢…í•© ë¦¬í¬íŠ¸\n",
    "    confusion_matrix     # í˜¼ë™ í–‰ë ¬: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í‘œë¡œ ì •ë¦¬\n",
    ")\n",
    "\n",
    "print(\"âœ… ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“š ì¤€ë¹„ëœ ëª¨ë¸:\")\n",
    "print(\"  1. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression) - ë¹ ë¥´ê³  í•´ì„í•˜ê¸° ì‰¬ì›€\")\n",
    "print(\"  2. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes) - í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— íŠ¹í™”\")\n",
    "print(\"  3. ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest) - ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ\")\n",
    "print(\"  4. SVM (Support Vector Machine) - ê³ ì„±ëŠ¥ ë¶„ë¥˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-1. ì „ì²˜ë¦¬ëœ ë¦¬ë·° ë°ì´í„° ë¡œë“œ\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ“‚ ì „ì²˜ë¦¬ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "print(\"   (ë°ì´í„°ê°€ ë§ì•„ì„œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\\n\")\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "# nrowsë¥¼ ì§€ì •í•˜ë©´ ì²˜ìŒ nê°œ í–‰ë§Œ ì½ìŒ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ nrows ì œê±°\n",
    "reviews = pd.read_csv('cleaned_reviews.csv')\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {reviews.shape[0]:,}ê°œ ë¦¬ë·°, {reviews.shape[1]}ê°œ ì»¬ëŸ¼\")\n",
    "\n",
    "# ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"\\nğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):\")\n",
    "print(\"=\"*80)\n",
    "reviews[['review_text', 'rating', 'is_recommended']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-2. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "# ============================================================\n",
    "# ê°ì„± ë¶„ì„ì— í•„ìš”í•œ ê²ƒ: ë¦¬ë·° í…ìŠ¤íŠ¸ì™€ ì¶”ì²œ ì—¬ë¶€\n",
    "\n",
    "print(\"ğŸ¯ ê°ì„± ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„° ì¤€ë¹„...\\n\")\n",
    "\n",
    "# review_textì™€ is_recommendedë§Œ ì„ íƒ\n",
    "# ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°\n",
    "data = reviews[['review_text', 'is_recommended']].dropna()\n",
    "\n",
    "print(f\"âœ… ì„ íƒ ì™„ë£Œ: {len(data):,}ê°œ ë¦¬ë·°\")\n",
    "\n",
    "# ì¶”ì²œ ì—¬ë¶€ ë¶„í¬ í™•ì¸\n",
    "print(\"\\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ (ì¶”ì²œ ì—¬ë¶€):\")\n",
    "print(\"=\"*80)\n",
    "class_dist = data['is_recommended'].value_counts()\n",
    "print(class_dist)\n",
    "print()\n",
    "for label, count in class_dist.items():\n",
    "    percentage = (count / len(data)) * 100\n",
    "    label_name = \"ì¶”ì²œ\" if label else \"ë¯¸ì¶”ì²œ\"\n",
    "    print(f\"{label_name}: {count:,}ê°œ ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-3. í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸ ë° ì²˜ë¦¬\n",
    "# ============================================================\n",
    "# í´ë˜ìŠ¤ ë¶ˆê· í˜•: í•œ í´ë˜ìŠ¤ì˜ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ì€ ê²½ìš°\n",
    "# ì˜ˆ: ê¸ì • 90%, ë¶€ì • 10% â†’ ëª¨ë¸ì´ í•­ìƒ ê¸ì •ìœ¼ë¡œ ì˜ˆì¸¡í•´ë„ 90% ì •í™•ë„!\n",
    "\n",
    "print(\"âš–ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸...\\n\")\n",
    "\n",
    "# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°\n",
    "positive_count = (data['is_recommended'] == True).sum()\n",
    "negative_count = (data['is_recommended'] == False).sum()\n",
    "imbalance_ratio = max(positive_count, negative_count) / min(positive_count, negative_count)\n",
    "\n",
    "print(f\"ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"\\nâš ï¸ ì‹¬í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. ì–¸ë”ìƒ˜í”Œë§: ë§ì€ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ì¤„ì„\")\n",
    "    print(\"   2. ì˜¤ë²„ìƒ˜í”Œë§: ì ì€ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ëŠ˜ë¦¼\")\n",
    "    print(\"   3. ê°€ì¤‘ì¹˜ ë¶€ì—¬: ì ì€ í´ë˜ìŠ¤ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜\")\n",
    "    print(\"\\n   â†’ ìš°ë¦¬ëŠ” ê°€ì¤‘ì¹˜ ë¶€ì—¬ ë°©ì‹ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"\\nâœ… í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels = ['ë¯¸ì¶”ì²œ', 'ì¶”ì²œ']\n",
    "counts = [negative_count, positive_count]\n",
    "colors = ['#ff6b6b', '#51cf66']\n",
    "\n",
    "bars = plt.bar(labels, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# ë§‰ëŒ€ ìœ„ì— ìˆ«ìì™€ ë¹„ìœ¨ í‘œì‹œ\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    percentage = (count / len(data)) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + len(data)*0.01,\n",
    "            f'{count:,}\\n({percentage:.1f}%)',\n",
    "            ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.title('í´ë˜ìŠ¤ ë¶„í¬ (ì¶”ì²œ ì—¬ë¶€)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('ë¦¬ë·° ìˆ˜', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "\n",
    "### ì™œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê°€ í•„ìš”í• ê¹Œ?\n",
    "\n",
    "ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë¬¸ì œê°€ ìƒê¹ë‹ˆë‹¤:\n",
    "- \"Good\", \"good\", \"GOOD\" â†’ ê°™ì€ ë‹¨ì–´ì§€ë§Œ ë‹¤ë¥´ê²Œ ì¸ì‹ë¨\n",
    "- \"!!!\", \"...\" â†’ ì˜ë¯¸ ì—†ëŠ” íŠ¹ìˆ˜ë¬¸ì\n",
    "- \"the\", \"is\", \"a\" â†’ ë„ˆë¬´ í”í•´ì„œ ì˜ë¯¸ ì—†ìŒ\n",
    "\n",
    "### ì „ì²˜ë¦¬ ë‹¨ê³„:\n",
    "1. **ì†Œë¬¸ì ë³€í™˜**: Good â†’ good\n",
    "2. **íŠ¹ìˆ˜ë¬¸ì ì œê±°**: \"amazing!!!\" â†’ \"amazing\"\n",
    "3. **ìˆ«ì ì œê±°**: \"2024\" â†’ \"\"\n",
    "4. **ë¶ˆìš©ì–´ ì œê±°**: \"the product is good\" â†’ \"product good\"\n",
    "5. **í† í°í™”**: \"I love this\" â†’ [\"I\", \"love\", \"this\"]\n",
    "\n",
    "### ì£¼ì˜:\n",
    "- ë„ˆë¬´ ë§ì´ ì „ì²˜ë¦¬í•˜ë©´ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë„ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- ì ì ˆí•œ ê· í˜•ì´ ì¤‘ìš”í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4-1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        ì›ë³¸ í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    cleaned_text : str\n",
    "        ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
    "    # \"AMAZING\" â†’ \"amazing\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³ê³¼ ê³µë°±ë§Œ ë‚¨ê¹€)\n",
    "    # re.sub(íŒ¨í„´, ëŒ€ì²´í• _ë¬¸ì, ì›ë³¸_ë¬¸ìì—´)\n",
    "    # [^a-z\\s]: ì•ŒíŒŒë²³(a-z)ê³¼ ê³µë°±(\\s)ì´ ì•„ë‹Œ ëª¨ë“  ê²ƒ\n",
    "    # ^ëŠ” 'ì•„ë‹Œ'ì„ ì˜ë¯¸\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. í† í°í™” (ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë‚˜ëˆ„ê¸°)\n",
    "    # \"I love this\" â†’ [\"I\", \"love\", \"this\"]\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # 4. ë¶ˆìš©ì–´ ì œê±°\n",
    "    # 'the', 'is', 'a' ê°™ì€ ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ì œê±°\n",
    "    # [ë‹¨ì–´ for ë‹¨ì–´ in ë¦¬ìŠ¤íŠ¸ if ì¡°ê±´]: ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜\n",
    "    # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‹¨ì–´ë§Œ ìƒˆ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # 5. ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±° (2ê¸€ì ì´í•˜)\n",
    "    # 'a', 'I' ê°™ì€ ë‹¨ì–´ ì œê±°\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    \n",
    "    # 6. ë‹¨ì–´ë“¤ì„ ë‹¤ì‹œ ë¬¸ì¥ìœ¼ë¡œ í•©ì¹˜ê¸°\n",
    "    # [\"love\", \"this\"] â†’ \"love this\"\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "test_texts = [\n",
    "    \"I LOVE this product!!! It's AMAZING ğŸ˜Š\",\n",
    "    \"This is the WORST product ever... Don't buy it!!!\",\n",
    "    \"Good quality for the price. I recommend it 100%!\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    cleaned = preprocess_text(text)\n",
    "    print(f\"ì˜ˆì‹œ {i}:\")\n",
    "    print(f\"  ì›ë³¸: {text}\")\n",
    "    print(f\"  ì „ì²˜ë¦¬ í›„: {cleaned}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4-2. ì „ì²´ ë°ì´í„°ì— ì „ì²˜ë¦¬ ì ìš©\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ”„ ì „ì²´ ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "print(\"   (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\\n\")\n",
    "\n",
    "# tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆìœ¼ë©´ ì§„í–‰ë°” í‘œì‹œ\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    # .apply()ì— progress_apply() ì‚¬ìš© (ì§„í–‰ë°” í‘œì‹œ)\n",
    "    tqdm.pandas(desc=\"ì „ì²˜ë¦¬ ì§„í–‰\")\n",
    "    data['cleaned_text'] = data['review_text'].progress_apply(preprocess_text)\n",
    "except ImportError:\n",
    "    # tqdmì´ ì—†ìœ¼ë©´ ì¼ë°˜ apply ì‚¬ìš©\n",
    "    data['cleaned_text'] = data['review_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\\n\")\n",
    "\n",
    "# ì „ì²˜ë¦¬ ê²°ê³¼ í™•ì¸\n",
    "print(\"ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ (ëœë¤ 3ê°œ):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ë¬´ì‘ìœ„ë¡œ 3ê°œ ì„ íƒ\n",
    "sample_indices = np.random.choice(len(data), size=3, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    original = data.iloc[idx]['review_text']\n",
    "    cleaned = data.iloc[idx]['cleaned_text']\n",
    "    label = \"ì¶”ì²œ\" if data.iloc[idx]['is_recommended'] else \"ë¯¸ì¶”ì²œ\"\n",
    "    \n",
    "    print(f\"\\nì˜ˆì‹œ {i} [{label}]:\")\n",
    "    print(f\"  ì›ë³¸ ({len(original)}ì):\")\n",
    "    print(f\"    {original[:200]}...\")  # ì²˜ìŒ 200ìë§Œ\n",
    "    print(f\"  ì „ì²˜ë¦¬ í›„ ({len(cleaned)}ì):\")\n",
    "    print(f\"    {cleaned[:200]}...\")  # ì²˜ìŒ 200ìë§Œ\n",
    "\n",
    "# ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°\n",
    "# ì „ì²˜ë¦¬ í›„ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì œê±°\n",
    "data = data[data['cleaned_text'].str.len() > 0]\n",
    "\n",
    "print(f\"\\n\\nğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°: {len(data):,}ê°œ ë¦¬ë·°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. í…ìŠ¤íŠ¸ ë²¡í„°í™” (Text Vectorization)\n",
    "\n",
    "### ì™œ ë²¡í„°í™”ê°€ í•„ìš”í• ê¹Œ?\n",
    "\n",
    "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ **ìˆ«ìë§Œ** ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë‘ ê°€ì§€ ë°©ë²•:\n",
    "\n",
    "#### 1. CountVectorizer (ë‹¨ì–´ ë¹ˆë„ìˆ˜)\n",
    "- ê° ë‹¨ì–´ê°€ ëª‡ ë²ˆ ë‚˜ì™”ëŠ”ì§€ ì„¸ê¸°\n",
    "- ì˜ˆì‹œ:\n",
    "  ```\n",
    "  ë¬¸ì¥: \"I love love this product\"\n",
    "  ê²°ê³¼: {\"I\":1, \"love\":2, \"this\":1, \"product\":1}\n",
    "  ë²¡í„°: [1, 2, 1, 1]\n",
    "  ```\n",
    "\n",
    "#### 2. TF-IDF (ë‹¨ì–´ ì¤‘ìš”ë„)\n",
    "- TF (Term Frequency): ë¬¸ì„œ ë‚´ ë‹¨ì–´ ë¹ˆë„\n",
    "- IDF (Inverse Document Frequency): ì „ì²´ ë¬¸ì„œì—ì„œ í¬ê·€í•œ ì •ë„\n",
    "- ê³µì‹: TF-IDF = TF Ã— IDF\n",
    "- ìì£¼ ë‚˜ì˜¤ì§€ë§Œ ì—¬ëŸ¬ ë¬¸ì„œì— ê³µí†µìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” ì¤‘ìš”ë„ ë‚®ìŒ\n",
    "- ì˜ˆ: \"good\"ì€ ëª¨ë“  ë¦¬ë·°ì— ë‚˜ì˜´ â†’ ì¤‘ìš”ë„ ë‚®ìŒ\n",
    "- ì˜ˆ: \"fragrance\"ëŠ” íŠ¹ì • ì œí’ˆ ë¦¬ë·°ì—ë§Œ ë‚˜ì˜´ â†’ ì¤‘ìš”ë„ ë†’ìŒ\n",
    "\n",
    "### ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í• ê¹Œ?\n",
    "- CountVectorizer: ê°„ë‹¨í•˜ê³  ë¹ ë¦„, ì´í•´í•˜ê¸° ì‰¬ì›€\n",
    "- TF-IDF: ë” ì •êµí•¨, ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë” ì¢‹ìŒ\n",
    "\n",
    "ìš°ë¦¬ëŠ” **TF-IDF**ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-1. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "# ============================================================\n",
    "# ë²¡í„°í™”í•˜ê¸° ì „ì— ë¨¼ì € ë°ì´í„°ë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤\n",
    "# ì™œ? í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì •ë³´ê°€ í•™ìŠµì— ìœ ì¶œë˜ëŠ” ê²ƒì„ ë°©ì§€\n",
    "\n",
    "print(\"âœ‚ï¸ ë°ì´í„°ë¥¼ í•™ìŠµìš©(80%)ê³¼ í…ŒìŠ¤íŠ¸ìš©(20%)ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì¤‘...\\n\")\n",
    "\n",
    "# X: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸\n",
    "X = data['cleaned_text']\n",
    "\n",
    "# y: ì¶”ì²œ ì—¬ë¶€ (True/False)\n",
    "y = data['is_recommended']\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "# stratify=y: í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ë¶„í• \n",
    "# ì˜ˆ: ì „ì²´ì—ì„œ ê¸ì • 80%ë©´, í•™ìŠµ/í…ŒìŠ¤íŠ¸ ëª¨ë‘ ê¸ì • 80%ë¡œ ìœ ì§€\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š ë°ì´í„° ë¶„í•  ê²°ê³¼:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(X):,}ê°œ\")\n",
    "print()\n",
    "print(f\"í•™ìŠµ ë°ì´í„°:\")\n",
    "print(f\"  - í¬ê¸°: {len(X_train):,}ê°œ ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - ì¶”ì²œ: {y_train.sum():,}ê°œ ({y_train.sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  - ë¯¸ì¶”ì²œ: {(~y_train).sum():,}ê°œ ({(~y_train).sum()/len(y_train)*100:.1f}%)\")\n",
    "print()\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°:\")\n",
    "print(f\"  - í¬ê¸°: {len(X_test):,}ê°œ ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - ì¶”ì²œ: {y_test.sum():,}ê°œ ({y_test.sum()/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  - ë¯¸ì¶”ì²œ: {(~y_test).sum():,}ê°œ ({(~y_test).sum()/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nâœ… stratify ë•ë¶„ì— í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-2. TF-IDF ë²¡í„°í™”\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ”¢ TF-IDFë¡œ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...\\n\")\n",
    "\n",
    "# TfidfVectorizer ìƒì„±\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # ê°€ì¥ ì¤‘ìš”í•œ 5000ê°œ ë‹¨ì–´ë§Œ ì‚¬ìš©\n",
    "    # ì™œ ì œí•œ? ëª¨ë“  ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ë²¡í„°ê°€ ë„ˆë¬´ ì»¤ì ¸ì„œ ëŠë ¤ì§\n",
    "    \n",
    "    min_df=5,  # ìµœì†Œ 5ê°œ ë¬¸ì„œì— ë‚˜íƒ€ë‚˜ì•¼ í•¨\n",
    "    # ë„ˆë¬´ í¬ê·€í•œ ë‹¨ì–´ëŠ” ì œì™¸ (ì˜¤íƒ€ì¼ ê°€ëŠ¥ì„±)\n",
    "    \n",
    "    max_df=0.8,  # ì „ì²´ ë¬¸ì„œì˜ 80% ì´ìƒì— ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ëŠ” ì œì™¸\n",
    "    # ë„ˆë¬´ í”í•œ ë‹¨ì–´ëŠ” ì˜ë¯¸ê°€ ì—†ìŒ\n",
    "    \n",
    "    ngram_range=(1, 2)  # 1ê°œ ë‹¨ì–´(unigram)ì™€ 2ê°œ ë‹¨ì–´(bigram)\n",
    "    # ì˜ˆ: \"not good\" â†’ \"not\", \"good\", \"not good\" ëª¨ë‘ ê³ ë ¤\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ë¡œ ë²¡í„°ë¼ì´ì € í•™ìŠµ\n",
    "# .fit(): ì–´ë–¤ ë‹¨ì–´ë“¤ì´ ìˆëŠ”ì§€ í•™ìŠµ, ê° ë‹¨ì–´ì— ì¸ë±ìŠ¤ ë¶€ì—¬\n",
    "print(\"1. í•™ìŠµ ë°ì´í„°ë¡œ ë²¡í„°ë¼ì´ì € í•™ìŠµ ì¤‘...\")\n",
    "vectorizer.fit(X_train)\n",
    "print(\"   âœ… ì™„ë£Œ\")\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ë³€í™˜\n",
    "# .transform(): í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜\n",
    "print(\"\\n2. í•™ìŠµ ë°ì´í„° ë³€í™˜ ì¤‘...\")\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "print(f\"   âœ… ì™„ë£Œ: {X_train_tfidf.shape}\")\n",
    "print(f\"   â†’ {X_train_tfidf.shape[0]:,}ê°œ ë¬¸ì„œ, {X_train_tfidf.shape[1]:,}ê°œ íŠ¹ì„±(ë‹¨ì–´)\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ (ê°™ì€ ë²¡í„°ë¼ì´ì € ì‚¬ìš©!)\n",
    "print(\"\\n3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ ì¤‘...\")\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(f\"   âœ… ì™„ë£Œ: {X_test_tfidf.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ë²¡í„°í™” ì™„ë£Œ!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì¶”ì¶œëœ ë‹¨ì–´(íŠ¹ì„±) í™•ì¸\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"\\nğŸ“Š ì¶”ì¶œëœ íŠ¹ì„±(ë‹¨ì–´) ìˆ˜: {len(feature_names):,}ê°œ\")\n",
    "print(f\"\\nì²˜ìŒ 20ê°œ ë‹¨ì–´:\")\n",
    "print(list(feature_names[:20]))\n",
    "print(f\"\\në§ˆì§€ë§‰ 20ê°œ ë‹¨ì–´:\")\n",
    "print(list(feature_names[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5-3. ë²¡í„°í™” ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ” ë²¡í„°í™” ê²°ê³¼ ì˜ˆì‹œ\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë¦¬ë·° í™•ì¸\n",
    "sample_idx = 0\n",
    "sample_text = X_train.iloc[sample_idx]\n",
    "sample_vector = X_train_tfidf[sample_idx]\n",
    "\n",
    "print(f\"ì›ë³¸ í…ìŠ¤íŠ¸:\")\n",
    "print(f\"  {sample_text}\")\n",
    "print()\n",
    "\n",
    "# ë²¡í„°ì—ì„œ 0ì´ ì•„ë‹Œ ê°’ë“¤ë§Œ ì¶”ì¶œ (ì¤‘ìš”í•œ ë‹¨ì–´ë“¤)\n",
    "# .nonzero()[1]: 0ì´ ì•„ë‹Œ ê°’ì˜ ì¸ë±ìŠ¤ë“¤\n",
    "nonzero_indices = sample_vector.nonzero()[1]\n",
    "\n",
    "print(f\"TF-IDF ë²¡í„° (0ì´ ì•„ë‹Œ ê°’ë§Œ):\")\n",
    "print(f\"  ì´ {len(nonzero_indices)}ê°œ ë‹¨ì–´\")\n",
    "print()\n",
    "\n",
    "# ìƒìœ„ 10ê°œ ì¤‘ìš” ë‹¨ì–´ ì¶œë ¥\n",
    "word_scores = [(feature_names[i], sample_vector[0, i]) for i in nonzero_indices]\n",
    "# TF-IDF ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "word_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"ê°€ì¥ ì¤‘ìš”í•œ 10ê°œ ë‹¨ì–´ (TF-IDF ì ìˆ˜):\")\n",
    "for i, (word, score) in enumerate(word_scores[:10], 1):\n",
    "    print(f\"  {i}. {word}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ í•´ì„:\")\n",
    "print(\"   - ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´ ë¦¬ë·°ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ì…ë‹ˆë‹¤\")\n",
    "print(\"   - 0ì¸ ë‹¨ì–´ëŠ” ì´ ë¦¬ë·°ì— ë‚˜íƒ€ë‚˜ì§€ ì•Šì€ ë‹¨ì–´ì…ë‹ˆë‹¤\")\n",
    "print(\"   - ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0ì…ë‹ˆë‹¤ (í¬ì†Œ í–‰ë ¬, Sparse Matrix)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "\n",
    "### ì‚¬ìš©í•  ëª¨ë¸ë“¤:\n",
    "\n",
    "#### 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\n",
    "- **ì›ë¦¬**: ì„ í˜• ëª¨ë¸ + ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ í™•ë¥  ê³„ì‚°\n",
    "- **ì¥ì **: ë¹ ë¥´ê³  í•´ì„í•˜ê¸° ì‰¬ì›€\n",
    "- **ë‹¨ì **: ë³µì¡í•œ íŒ¨í„´ì€ í•™ìŠµ ëª»í•¨\n",
    "\n",
    "#### 2. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes)\n",
    "- **ì›ë¦¬**: ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ì´ìš©í•œ í™•ë¥  ê³„ì‚°\n",
    "- **ì¥ì **: í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— ë§¤ìš° íš¨ê³¼ì , ë¹ ë¦„\n",
    "- **ë‹¨ì **: ë‹¨ì–´ë“¤ì´ ë…ë¦½ì ì´ë¼ê³  ê°€ì • (ì‹¤ì œë¡œëŠ” ì•„ë‹˜)\n",
    "\n",
    "#### 3. ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)\n",
    "- **ì›ë¦¬**: ì—¬ëŸ¬ ê²°ì • íŠ¸ë¦¬ì˜ íˆ¬í‘œ\n",
    "- **ì¥ì **: ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥\n",
    "- **ë‹¨ì **: ëŠë¦¼, ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
    "\n",
    "#### 4. SVM (Support Vector Machine)\n",
    "- **ì›ë¦¬**: ìµœì ì˜ ê²°ì • ê²½ê³„ ì°¾ê¸°\n",
    "- **ì¥ì **: ê³ ì°¨ì› ë°ì´í„°ì— íš¨ê³¼ì \n",
    "- **ë‹¨ì **: í° ë°ì´í„°ì…‹ì—ì„œëŠ” ëŠë¦¼\n",
    "\n",
    "### í‰ê°€ ì§€í‘œ:\n",
    "\n",
    "#### í˜¼ë™ í–‰ë ¬ (Confusion Matrix):\n",
    "```\n",
    "                ì˜ˆì¸¡: ë¯¸ì¶”ì²œ    ì˜ˆì¸¡: ì¶”ì²œ\n",
    "ì‹¤ì œ: ë¯¸ì¶”ì²œ    TN (ë§ìŒ)     FP (í‹€ë¦¼)\n",
    "ì‹¤ì œ: ì¶”ì²œ      FN (í‹€ë¦¼)     TP (ë§ìŒ)\n",
    "```\n",
    "\n",
    "#### ì§€í‘œë“¤:\n",
    "- **ì •í™•ë„ (Accuracy)**: (TP + TN) / ì „ì²´  \n",
    "  â†’ ì „ì²´ ì¤‘ ë§ì¶˜ ë¹„ìœ¨\n",
    "\n",
    "- **ì •ë°€ë„ (Precision)**: TP / (TP + FP)  \n",
    "  â†’ ì¶”ì²œìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ì¶”ì²œ ë¹„ìœ¨  \n",
    "  â†’ ë†’ìœ¼ë©´: ì¶”ì²œìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ ì •ë§ ì¶”ì²œì¼ í™•ë¥ ì´ ë†’ìŒ\n",
    "\n",
    "- **ì¬í˜„ìœ¨ (Recall)**: TP / (TP + FN)  \n",
    "  â†’ ì‹¤ì œ ì¶”ì²œ ì¤‘ ì¶”ì²œìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨  \n",
    "  â†’ ë†’ìœ¼ë©´: ì¶”ì²œì„ ì˜ ì°¾ì•„ëƒ„\n",
    "\n",
    "- **F1 Score**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)  \n",
    "  â†’ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê·   \n",
    "  â†’ ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-1. ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_classifier(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ¤– {model_name} í•™ìŠµ ì¤‘...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"âœ… í•™ìŠµ ì™„ë£Œ!\\n\")\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"ğŸ“Š í•™ìŠµ ë°ì´í„° ì„±ëŠ¥:\")\n",
    "    print(f\"   ì •í™•ë„: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥: (ì§„ì§œ ì„±ëŠ¥!)\")\n",
    "    print(f\"   ì •í™•ë„ (Accuracy)  : {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    print(f\"   ì •ë°€ë„ (Precision) : {test_precision:.4f}\")\n",
    "    print(f\"   ì¬í˜„ìœ¨ (Recall)    : {test_recall:.4f}\")\n",
    "    print(f\"   F1 Score          : {test_f1:.4f}\")\n",
    "    \n",
    "    # ê³¼ì í•© ì²´í¬\n",
    "    if train_accuracy - test_accuracy > 0.05:\n",
    "        print(\"\\nâš ï¸ ê³¼ì í•© ê°€ëŠ¥ì„±: í•™ìŠµ ë°ì´í„° ì„±ëŠ¥ì´ í…ŒìŠ¤íŠ¸ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâœ… ê³¼ì í•© ì—†ìŒ: í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ì´ ë¹„ìŠ·í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # í˜¼ë™ í–‰ë ¬\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['ë¯¸ì¶”ì²œ', 'ì¶”ì²œ'],\n",
    "                yticklabels=['ë¯¸ì¶”ì²œ', 'ì¶”ì²œ'])\n",
    "    plt.title(f'í˜¼ë™ í–‰ë ¬ - {model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('ì‹¤ì œ', fontsize=12)\n",
    "    plt.xlabel('ì˜ˆì¸¡', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # í˜¼ë™ í–‰ë ¬ ì„¤ëª…\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"\\nğŸ“Š í˜¼ë™ í–‰ë ¬ í•´ì„:\")\n",
    "    print(f\"   TN (ì°¸ ë¶€ì •): {tn:,}ê°œ - ë¯¸ì¶”ì²œì„ ë¯¸ì¶”ì²œìœ¼ë¡œ ë§ì¶¤ âœ“\")\n",
    "    print(f\"   FP (ê±°ì§“ ê¸ì •): {fp:,}ê°œ - ë¯¸ì¶”ì²œì„ ì¶”ì²œìœ¼ë¡œ í‹€ë¦¼ âœ—\")\n",
    "    print(f\"   FN (ê±°ì§“ ë¶€ì •): {fn:,}ê°œ - ì¶”ì²œì„ ë¯¸ì¶”ì²œìœ¼ë¡œ í‹€ë¦¼ âœ—\")\n",
    "    print(f\"   TP (ì°¸ ê¸ì •): {tp:,}ê°œ - ì¶”ì²œì„ ì¶”ì²œìœ¼ë¡œ ë§ì¶¤ âœ“\")\n",
    "    \n",
    "    # ìƒì„¸ ë¦¬í¬íŠ¸\n",
    "    print(\"\\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\")\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(y_test, y_test_pred, \n",
    "                                target_names=['ë¯¸ì¶”ì²œ', 'ì¶”ì²œ']))\n",
    "    \n",
    "    # ê²°ê³¼ ë°˜í™˜\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… í‰ê°€ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-2. ëª¨ë¸ 1 - ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ëª¨ë¸ 1: ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nğŸ“– ë¡œì§€ìŠ¤í‹± íšŒê·€ë€?\")\n",
    "print(\"   ì„ í˜• íšŒê·€ + ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\")\n",
    "print(\"   ì¶œë ¥ì´ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë‚˜ì˜¤ë©°, 0.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.\")\n",
    "print(\"   ë¹ ë¥´ê³  í•´ì„í•˜ê¸° ì‰¬ì›Œì„œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë¡œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„±\n",
    "# max_iter=1000: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜\n",
    "# class_weight='balanced': í´ë˜ìŠ¤ ë¶ˆê· í˜• ìë™ ì²˜ë¦¬\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "lr_results = evaluate_classifier(\n",
    "    model=lr_model,\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-3. ëª¨ë¸ 2 - ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ëª¨ë¸ 2: ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes)\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nğŸ“– ë‚˜ì´ë¸Œ ë² ì´ì¦ˆë€?\")\n",
    "print(\"   ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ì´ìš©í•œ í™•ë¥  ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ì…ë‹ˆë‹¤.\")\n",
    "print(\"   ê° ë‹¨ì–´ê°€ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.\")\n",
    "print(\"   í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— ë§¤ìš° íš¨ê³¼ì ì´ê³  ë¹ ë¦…ë‹ˆë‹¤.\")\n",
    "print(\"   ìŠ¤íŒ¸ í•„í„°, ë¬¸ì„œ ë¶„ë¥˜ ë“±ì— ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ ìƒì„±\n",
    "# MultinomialNB: ë‹¤í•­ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (ë‹¨ì–´ ë¹ˆë„ì— ì í•©)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "nb_results = evaluate_classifier(\n",
    "    model=nb_model,\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-4. ëª¨ë¸ 3 - ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ëª¨ë¸ 3: ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nğŸ“– ëœë¤ í¬ë ˆìŠ¤íŠ¸ë€?\")\n",
    "print(\"   ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì–´ì„œ íˆ¬í‘œë¡œ ê²°ì •í•©ë‹ˆë‹¤.\")\n",
    "print(\"   ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ë„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"   ê³¼ì í•©ì— ê°•í•˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.\")\n",
    "\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„±\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # 100ê°œì˜ íŠ¸ë¦¬\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # ëª¨ë“  CPU ì‚¬ìš©\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "rf_results = evaluate_classifier(\n",
    "    model=rf_model,\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6-5. ëª¨ë¸ 4 - SVM (Support Vector Machine)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ëª¨ë¸ 4: SVM (Support Vector Machine)\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nğŸ“– SVMì´ë€?\")\n",
    "print(\"   ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ êµ¬ë¶„í•˜ëŠ” ê²½ê³„ì„ (ì´ˆí‰ë©´)ì„ ì°¾ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\")\n",
    "print(\"   ë§ˆì§„(ì—¬ìœ  ê³µê°„)ì„ ìµœëŒ€í™”í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤.\")\n",
    "print(\"   ê³ ì°¨ì› ë°ì´í„°(í…ìŠ¤íŠ¸)ì— ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# SVM ëª¨ë¸ ìƒì„±\n",
    "# LinearSVC: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ëŠ” ë¹ ë¥¸ SVM\n",
    "svm_model = LinearSVC(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "svm_results = evaluate_classifier(\n",
    "    model=svm_model,\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"SVM (Support Vector Machine)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ëª¨ë¸ ë¹„êµ ë° ìµœì¢… ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7-1. ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµí‘œ ìƒì„±\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ëª¨ë“  ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'ëª¨ë¸': lr_results['model_name'],\n",
    "        'ì •í™•ë„': lr_results['test_accuracy'],\n",
    "        'ì •ë°€ë„': lr_results['test_precision'],\n",
    "        'ì¬í˜„ìœ¨': lr_results['test_recall'],\n",
    "        'F1 Score': lr_results['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'ëª¨ë¸': nb_results['model_name'],\n",
    "        'ì •í™•ë„': nb_results['test_accuracy'],\n",
    "        'ì •ë°€ë„': nb_results['test_precision'],\n",
    "        'ì¬í˜„ìœ¨': nb_results['test_recall'],\n",
    "        'F1 Score': nb_results['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'ëª¨ë¸': rf_results['model_name'],\n",
    "        'ì •í™•ë„': rf_results['test_accuracy'],\n",
    "        'ì •ë°€ë„': rf_results['test_precision'],\n",
    "        'ì¬í˜„ìœ¨': rf_results['test_recall'],\n",
    "        'F1 Score': rf_results['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'ëª¨ë¸': svm_results['model_name'],\n",
    "        'ì •í™•ë„': svm_results['test_accuracy'],\n",
    "        'ì •ë°€ë„': svm_results['test_precision'],\n",
    "        'ì¬í˜„ìœ¨': svm_results['test_recall'],\n",
    "        'F1 Score': svm_results['test_f1']\n",
    "    }\n",
    "])\n",
    "\n",
    "# F1 Score ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "comparison = comparison.sort_values('F1 Score', ascending=False)\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "best_model_name = comparison.iloc[0]['ëª¨ë¸']\n",
    "best_f1 = comparison.iloc[0]['F1 Score']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}\")\n",
    "print(f\"   F1 Score: {best_f1:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7-2. ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”\n",
    "# ============================================================\n",
    "\n",
    "# ê·¸ë˜í”„ í¬ê¸° ì„¤ì •\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. ì •í™•ë„ ë¹„êµ\n",
    "axes[0, 0].bar(comparison['ëª¨ë¸'], comparison['ì •í™•ë„'], \n",
    "               color='skyblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('ì •í™•ë„ (Accuracy)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('ì ìˆ˜', fontsize=12)\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "for i, (model, acc) in enumerate(zip(comparison['ëª¨ë¸'], comparison['ì •í™•ë„'])):\n",
    "    axes[0, 0].text(i, acc + 0.02, f'{acc:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. ì •ë°€ë„ ë¹„êµ\n",
    "axes[0, 1].bar(comparison['ëª¨ë¸'], comparison['ì •ë°€ë„'], \n",
    "               color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('ì •ë°€ë„ (Precision)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('ì ìˆ˜', fontsize=12)\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "for i, (model, prec) in enumerate(zip(comparison['ëª¨ë¸'], comparison['ì •ë°€ë„'])):\n",
    "    axes[0, 1].text(i, prec + 0.02, f'{prec:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. ì¬í˜„ìœ¨ ë¹„êµ\n",
    "axes[1, 0].bar(comparison['ëª¨ë¸'], comparison['ì¬í˜„ìœ¨'], \n",
    "               color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('ì¬í˜„ìœ¨ (Recall)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('ì ìˆ˜', fontsize=12)\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "for i, (model, rec) in enumerate(zip(comparison['ëª¨ë¸'], comparison['ì¬í˜„ìœ¨'])):\n",
    "    axes[1, 0].text(i, rec + 0.02, f'{rec:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 4. F1 Score ë¹„êµ\n",
    "axes[1, 1].bar(comparison['ëª¨ë¸'], comparison['F1 Score'], \n",
    "               color='gold', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('F1 Score (ì¢…í•© ì ìˆ˜)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('ì ìˆ˜', fontsize=12)\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "for i, (model, f1) in enumerate(zip(comparison['ëª¨ë¸'], comparison['F1 Score'])):\n",
    "    axes[1, 1].text(i, f1 + 0.02, f'{f1:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š ê·¸ë˜í”„ ì„¤ëª…:\")\n",
    "print(\"   - ì •í™•ë„: ì „ì²´ ì¤‘ ë§ì¶˜ ë¹„ìœ¨\")\n",
    "print(\"   - ì •ë°€ë„: ì¶”ì²œìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ì¶”ì²œ ë¹„ìœ¨\")\n",
    "print(\"   - ì¬í˜„ìœ¨: ì‹¤ì œ ì¶”ì²œ ì¤‘ ì¶”ì²œìœ¼ë¡œ ì˜ˆì¸¡í•œ ë¹„ìœ¨\")\n",
    "print(\"   - F1 Score: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê·  (ì¢…í•© ì§€í‘œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. ì‹¤ì œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8-1. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "# ============================================================\n",
    "\n",
    "# F1 Scoreê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ ì„ íƒ\n",
    "all_results = [lr_results, nb_results, rf_results, svm_results]\n",
    "best_result = max(all_results, key=lambda x: x['test_f1'])\n",
    "\n",
    "print(f\"ğŸ† ì„ íƒëœ ëª¨ë¸: {best_result['model_name']}\")\n",
    "print(f\"   F1 Score: {best_result['test_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8-2. ìƒˆë¡œìš´ ë¦¬ë·°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nğŸ§ª ìƒˆë¡œìš´ ë¦¬ë·°ë¡œ ê°ì„± ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ìƒˆë¡œìš´ ë¦¬ë·°ë“¤\n",
    "new_reviews = [\n",
    "    \"This product is absolutely amazing! I love it so much and highly recommend it to everyone!\",\n",
    "    \"Terrible product. Complete waste of money. Do not buy this!\",\n",
    "    \"It's okay, nothing special. Works as expected but not impressed.\",\n",
    "    \"Best purchase ever! My skin has never looked better. Will definitely buy again!\",\n",
    "    \"Horrible! Caused allergic reaction. Very disappointed and angry.\"\n",
    "]\n",
    "\n",
    "# ê° ë¦¬ë·° ì˜ˆì¸¡\n",
    "for i, review in enumerate(new_reviews, 1):\n",
    "    # ì „ì²˜ë¦¬\n",
    "    cleaned = preprocess_text(review)\n",
    "    \n",
    "    # ë²¡í„°í™”\n",
    "    vectorized = vectorizer.transform([cleaned])\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    prediction = best_result['model'].predict(vectorized)[0]\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "    if hasattr(best_result['model'], 'predict_proba'):\n",
    "        proba = best_result['model'].predict_proba(vectorized)[0]\n",
    "        confidence = proba[1] if prediction else proba[0]\n",
    "    elif hasattr(best_result['model'], 'decision_function'):\n",
    "        # SVMì˜ ê²½ìš°\n",
    "        decision = best_result['model'].decision_function(vectorized)[0]\n",
    "        # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ í™•ë¥  ê·¼ì‚¬\n",
    "        confidence = 1 / (1 + np.exp(-decision))\n",
    "        if not prediction:\n",
    "            confidence = 1 - confidence\n",
    "    else:\n",
    "        confidence = None\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    result_text = \"âœ… ì¶”ì²œ\" if prediction else \"âŒ ë¯¸ì¶”ì²œ\"\n",
    "    print(f\"\\në¦¬ë·° {i}:\")\n",
    "    print(f\"  ì›ë³¸: {review}\")\n",
    "    print(f\"  ì˜ˆì¸¡: {result_text}\")\n",
    "    if confidence is not None:\n",
    "        print(f\"  í™•ì‹ ë„: {confidence:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8-3. ìƒ˜í”Œ ë¦¬ë·° ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ (ë¬´ì‘ìœ„ 10ê°œ):\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ë¬´ì‘ìœ„ë¡œ 10ê°œ ì„ íƒ\n",
    "sample_indices = np.random.choice(len(X_test), size=min(10, len(X_test)), replace=False)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred = best_result['model'].predict(X_test_tfidf)\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    original_text = X_test.iloc[idx]\n",
    "    actual = \"ì¶”ì²œ\" if y_test.iloc[idx] else \"ë¯¸ì¶”ì²œ\"\n",
    "    predicted = \"ì¶”ì²œ\" if y_pred[idx] else \"ë¯¸ì¶”ì²œ\"\n",
    "    correct = \"âœ“\" if y_test.iloc[idx] == y_pred[idx] else \"âœ—\"\n",
    "    \n",
    "    print(f\"\\n{i}. {correct}\")\n",
    "    print(f\"   ë¦¬ë·°: {original_text[:100]}...\")  # ì²˜ìŒ 100ìë§Œ\n",
    "    print(f\"   ì‹¤ì œ: {actual} | ì˜ˆì¸¡: {predicted}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. í•™ìŠµ ìš”ì•½ ë° ê²°ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. ìµœì¢… ìš”ì•½\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ğŸ“ ë¦¬ë·° ê°ì„± ë¶„ì„ - ìµœì¢… ìš”ì•½\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {len(data):,}ê°œ ë¦¬ë·°\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê°œ ({len(X_train)/len(data)*100:.1f}%)\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê°œ ({len(X_test)/len(data)*100:.1f}%)\")\n",
    "print(f\"íŠ¹ì„± ì°¨ì›: {X_train_tfidf.shape[1]:,}ê°œ (TF-IDF ë²¡í„°)\")\n",
    "\n",
    "print(\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ëª¨ë¸: {best_result['model_name']}\")\n",
    "print(f\"ì •í™•ë„: {best_result['test_accuracy']:.4f} ({best_result['test_accuracy']*100:.2f}%)\")\n",
    "print(f\"ì •ë°€ë„: {best_result['test_precision']:.4f}\")\n",
    "print(f\"ì¬í˜„ìœ¨: {best_result['test_recall']:.4f}\")\n",
    "print(f\"F1 Score: {best_result['test_f1']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ë°°ìš´ ë‚´ìš©:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. ë¶„ë¥˜(Classification) ë¬¸ì œì˜ ì´í•´\")\n",
    "print(\"   - ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë‚˜ëˆ„ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•\")\n",
    "print(\"   - íšŒê·€ì™€ì˜ ì°¨ì´: ìˆ«ì vs ì¹´í…Œê³ ë¦¬\")\n",
    "\n",
    "print(\"\\n2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\")\n",
    "print(\"   - ì†Œë¬¸ì ë³€í™˜, íŠ¹ìˆ˜ë¬¸ì ì œê±°\")\n",
    "print(\"   - ë¶ˆìš©ì–´ ì œê±° (ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´)\")\n",
    "print(\"   - í† í°í™” (ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë‚˜ëˆ„ê¸°)\")\n",
    "\n",
    "print(\"\\n3. í…ìŠ¤íŠ¸ ë²¡í„°í™”\")\n",
    "print(\"   - TF-IDF: ë‹¨ì–´ì˜ ë¹ˆë„ì™€ ì¤‘ìš”ë„ë¥¼ í•¨ê»˜ ê³ ë ¤\")\n",
    "print(\"   - í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜\")\n",
    "print(\"   - í¬ì†Œ í–‰ë ¬ (Sparse Matrix): ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0\")\n",
    "\n",
    "print(\"\\n4. ì—¬ëŸ¬ ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ\")\n",
    "print(\"   - ë¡œì§€ìŠ¤í‹± íšŒê·€: ë¹ ë¥´ê³  í•´ì„í•˜ê¸° ì‰¬ì›€\")\n",
    "print(\"   - ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ: í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— íŠ¹í™”\")\n",
    "print(\"   - ëœë¤ í¬ë ˆìŠ¤íŠ¸: ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ\")\n",
    "print(\"   - SVM: ê³ ì°¨ì› ë°ì´í„°ì— íš¨ê³¼ì \")\n",
    "\n",
    "print(\"\\n5. ëª¨ë¸ í‰ê°€\")\n",
    "print(\"   - ì •í™•ë„: ì „ì²´ ì¤‘ ë§ì¶˜ ë¹„ìœ¨\")\n",
    "print(\"   - ì •ë°€ë„: ê¸ì • ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ê¸ì •\")\n",
    "print(\"   - ì¬í˜„ìœ¨: ì‹¤ì œ ê¸ì • ì¤‘ ê¸ì • ì˜ˆì¸¡\")\n",
    "print(\"   - F1 Score: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· \")\n",
    "print(\"   - í˜¼ë™ í–‰ë ¬: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í‘œë¡œ ì •ë¦¬\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ğŸ¯ ë‹¤ìŒ ë‹¨ê³„\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\në‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ê³„ì†:\")\n",
    "print(\"  - 05_ml_recommendation_system.ipynb: ì œí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ\")\n",
    "print(\"  - 06_ml_review_helpfulness.ipynb: ë¦¬ë·° ìœ ìš©ì„± ì˜ˆì¸¡\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ë…¸íŠ¸ë¶ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
