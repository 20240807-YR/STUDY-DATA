{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9363c28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í¬ë¡¤ë§: https://www.coupang.com/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# í…ŒìŠ¤íŠ¸ (í™ˆ ì¸ê¸°ìƒí’ˆ íƒ­ ê°™ì€ ê³³ URL ë„£ìœ¼ë©´ ë¨)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.coupang.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m crawl_coupang(url)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì´ ê°œìˆ˜:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mcrawl_coupang\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcrawl_coupang\u001b[39m(url):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mí¬ë¡¤ë§:\u001b[39m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[0;32m---> 12\u001b[0m     r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     13\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     items \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli.carousel-item.fw-group\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    717\u001b[0m     conn,\n\u001b[1;32m    718\u001b[0m     method,\n\u001b[1;32m    719\u001b[0m     url,\n\u001b[1;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/urllib3/connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "def crawl_coupang(url):\n",
    "    print(\"í¬ë¡¤ë§:\", url)\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    items = soup.select(\"li.carousel-item.fw-group\")\n",
    "    results = []\n",
    "\n",
    "    for item in items:\n",
    "        # ì´ë¯¸ì§€\n",
    "        img_tag = item.select_one(\"div.item-image img\")\n",
    "        img = img_tag.get(\"src\") if img_tag else None\n",
    "        alt = img_tag.get(\"alt\") if img_tag else None\n",
    "\n",
    "        # ì œí’ˆëª…\n",
    "        name_tag = item.select_one(\"div.item-info-wrap .name\")\n",
    "        name = name_tag.get_text(strip=True) if name_tag else alt\n",
    "\n",
    "        # ê°€ê²©\n",
    "        price_tag = item.select_one(\".price-value\")\n",
    "        price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": name,\n",
    "            \"price\": price,\n",
    "            \"image\": img,\n",
    "            \"alt_name\": alt\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "url = \"https://www.coupang.com/\"\n",
    "df = crawl_coupang(url)\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì´ ê°œìˆ˜:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcaac969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless=new\")   # í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "def crawl_coupang_list(url, scroll_count=5, scroll_pause=2.0):\n",
    "    driver = get_driver()\n",
    "    driver.get(url)\n",
    "\n",
    "    # --- ìŠ¤í¬ë¡¤ ë‹¤ìš´ ---\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_count):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # --- HTML ê°€ì ¸ì˜¤ê¸° ---\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # ğŸ”¥ ë„¤ DOM ê¸°ë°˜ ì •í™•í•œ selector\n",
    "    items = soup.select(\"li.carousel-item\")\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        # 1) ìƒí’ˆ ì´ë¯¸ì§€ / ì´ë¦„\n",
    "        img = it.select_one(\"div.item-image img\")\n",
    "        name = img.get(\"alt\").strip() if img and img.get(\"alt\") else None\n",
    "\n",
    "        # 2) ìƒì„¸ ë§í¬\n",
    "        a_tag = it.select_one(\"a\")\n",
    "        href = a_tag.get(\"href\") if a_tag and a_tag.get(\"href\") else None\n",
    "        if href and href.startswith(\"/\"):\n",
    "            href = \"https://www.coupang.com\" + href\n",
    "\n",
    "        # 3) ê°€ê²© (ì¿ íŒ¡ ê¸°ë³¸ selector)\n",
    "        price_el = it.select_one(\"strong.price-value\")\n",
    "        price = price_el.get_text(strip=True) if price_el else None\n",
    "\n",
    "        # 4) ë¸Œëœë“œ\n",
    "        brand_el = it.select_one(\"span.seller, span.brand\")\n",
    "        brand = brand_el.get_text(strip=True) if brand_el else None\n",
    "\n",
    "        # 5) í‰ì \n",
    "        rating_el = it.select_one(\"em.rating\")\n",
    "        rating = rating_el.get_text(strip=True) if rating_el else None\n",
    "\n",
    "        # 6) ë¦¬ë·° ìˆ˜\n",
    "        review_el = it.select_one(\"span.rating-total-count\")\n",
    "        review_cnt = (\n",
    "            review_el.get_text(strip=True).strip(\"()\")\n",
    "            if review_el\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        if not name:\n",
    "            continue  # ì´ë¦„ ì—†ëŠ” ì¹´ë“œë©´ skip\n",
    "\n",
    "        rows.append({\n",
    "            \"name\": name,\n",
    "            \"brand\": brand,\n",
    "            \"price\": price,\n",
    "            \"rating\": rating,\n",
    "            \"review_count\": review_cnt,\n",
    "            \"link\": href\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4daf12bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ì´ ê°œìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.coupang.com/\"\n",
    "df = crawl_coupang_list(url, scroll_count=8, scroll_pause=2.0)\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì´ ê°œìˆ˜:\", len(df))\n",
    "\n",
    "df.to_csv(\"coupang_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cd2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless=new\")  # í•„ìš”í•˜ë©´ ì¼œê¸°\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "def crawl_coupang_search(url, scroll_count=5, scroll_pause=2.0):\n",
    "    driver = get_driver()\n",
    "    driver.get(url)\n",
    "\n",
    "    # ----- ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤í•´ì„œ ìƒí’ˆ ë” ë¡œë”© -----\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_count):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # ğŸ”¥ ê²€ìƒ‰/ì¹´í…Œê³ ë¦¬ ìƒí’ˆ ì¹´ë“œ ì„ íƒì\n",
    "    items = soup.select(\"li.search-product\")\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        # ìƒí’ˆëª…\n",
    "        name_el = it.select_one(\"div.name\")\n",
    "        name = name_el.get_text(strip=True) if name_el else None\n",
    "\n",
    "        # ìƒì„¸ ë§í¬\n",
    "        a_tag = it.select_one(\"a\")\n",
    "        href = a_tag.get(\"href\") if a_tag and a_tag.get(\"href\") else None\n",
    "        if href and href.startswith(\"/\"):\n",
    "            href = \"https://www.coupang.com\" + href\n",
    "\n",
    "        # ê°€ê²©\n",
    "        price_el = it.select_one(\"strong.price-value\")\n",
    "        price = price_el.get_text(strip=True) if price_el else None\n",
    "\n",
    "        # ë¸Œëœë“œ\n",
    "        brand_el = it.select_one(\"div.prod-brand-name\")\n",
    "        brand = brand_el.get_text(strip=True) if brand_el else None\n",
    "\n",
    "        # í‰ì \n",
    "        rating_el = it.select_one(\"em.rating\")\n",
    "        rating = rating_el.get_text(strip=True) if rating_el else None\n",
    "\n",
    "        # ë¦¬ë·° ìˆ˜\n",
    "        review_el = it.select_one(\"span.rating-total-count\")\n",
    "        review_cnt = (\n",
    "            review_el.get_text(strip=True).strip(\"()\")\n",
    "            if review_el else None\n",
    "        )\n",
    "\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"name\": name,\n",
    "            \"brand\": brand,\n",
    "            \"price\": price,\n",
    "            \"rating\": rating,\n",
    "            \"review_count\": review_cnt,\n",
    "            \"link\": href,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fc48b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ì´ ê°œìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.coupang.com/np/search?q=%EC%96%B4%EC%84%B1%EC%B4%88+%ED%86%A0%EB%84%88+%ED%8C%A8%EB%93%9C&listSize=60\"\n",
    "\n",
    "df = crawl_coupang_search(url, scroll_count=5, scroll_pause=2.0)\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì´ ê°œìˆ˜:\", len(df))\n",
    "\n",
    "df.to_csv(\"coupang_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874c4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    # í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œí•´ì„œ ì°½ ì•ˆ ëœ¨ê²Œ\n",
    "    # options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "def crawl_coupang_search(url, scroll_count=5, scroll_pause=2.0):\n",
    "    driver = get_driver()\n",
    "    driver.get(url)\n",
    "\n",
    "    # ----- ì•„ë˜ë¡œ ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤í•´ì„œ ìƒí’ˆ ë” ë¡œë”© -----\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_count):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # ğŸ”¥ ê²€ìƒ‰/ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ìš© ìƒí’ˆ ì¹´ë“œ ì„ íƒì\n",
    "    items = soup.select(\"li.search-product\")\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        name_el = it.select_one(\"div.name\")\n",
    "        name = name_el.get_text(strip=True) if name_el else None\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        a_tag = it.select_one(\"a\")\n",
    "        href = a_tag.get(\"href\") if a_tag and a_tag.get(\"href\") else None\n",
    "        if href and href.startswith(\"/\"):\n",
    "            href = \"https://www.coupang.com\" + href\n",
    "\n",
    "        price_el = it.select_one(\"strong.price-value\")\n",
    "        price = price_el.get_text(strip=True) if price_el else None\n",
    "\n",
    "        brand_el = it.select_one(\"div.prod-brand-name\")\n",
    "        brand = brand_el.get_text(strip=True) if brand_el else None\n",
    "\n",
    "        rating_el = it.select_one(\"em.rating\")\n",
    "        rating = rating_el.get_text(strip=True) if rating_el else None\n",
    "\n",
    "        review_el = it.select_one(\"span.rating-total-count\")\n",
    "        review_cnt = review_el.get_text(strip=True).strip(\"()\") if review_el else None\n",
    "\n",
    "        rows.append({\n",
    "            \"name\": name,\n",
    "            \"brand\": brand,\n",
    "            \"price\": price,\n",
    "            \"rating\": rating,\n",
    "            \"review_count\": review_cnt,\n",
    "            \"link\": href,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102e88d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ì´ ê°œìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.coupang.com/np/search?q=%EC%96%B4%EC%84%B1%EC%B4%88+%ED%86%A0%EB%84%88+%ED%8C%A8%EB%93%9C&listSize=60\"\n",
    "\n",
    "df = crawl_coupang_search(url, scroll_count=5, scroll_pause=2.0)\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì´ ê°œìˆ˜:\", len(df))\n",
    "\n",
    "df.to_csv(\"coupang_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d989c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
